import streamlit as st
import os
import json
from openai import OpenAI
from pathlib import Path
import pandas as pd

# é¢„è®¾çš„system prompts
DEFAULT_PROMPTS = {
    "é€šç”¨åŠ©æ‰‹": "You are a helpful assistant.",
    "æ–‡ç« æ€»ç»“": "You are an expert at summarizing text. Please provide a concise summary in Chinese.",
    "æ–‡æ¡£è½¬æ–‡ç¨¿": "å°†ç”¨æˆ·è¾“å…¥çš„å†…å®¹è½¬æ¢ä¸ºæ–‡ç¨¿ï¼Œè¦æ±‚æœ€å¤§ç¨‹åº¦çš„ä¿ç•™ä¿¡æ¯å®Œæ•´ï¼Œä½†ä¸åŒ…å«ä»»ä½•mdæ ¼å¼ï¼Œä¸è¦ä½¿ç”¨åˆ—è¡¨æ ¼å¼ã€‚å¦‚æœæœ‰emojiï¼Œåˆ™è½¬æ¢ä¸ºç›¸åº”æ–‡æœ¬ã€‚è¡¨ç¤ºç®­å¤´çš„ç¬¦å·ç»„åˆï¼Œä¾‹å¦‚ï¼š'->'ä½¿ç”¨'>'è¡¨ç¤ºï¼Œ'<-'ä½¿ç”¨'<'è¡¨ç¤ºã€‚",
    "SRTå­—å¹•åˆ›å»ºæ¦‚æ‹¬æ€§ç¬”è®°": "ä½ æ˜¯ä¸€ä¸ªAIå­¦ä¹ åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·æä¾›çš„SRTå­—å¹•æ–‡ä»¶ç”Ÿæˆç»“æ„åŒ–çš„Markdownæ ¼å¼ç¬”è®°æˆ–çŸ¥è¯†æ€»ç»“ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¤„ç†è¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªä¾¿äºå¤ä¹ å’Œå®šä½çš„Markdownæ–‡æ¡£ï¼š\n\nè¾“å…¥è§£æï¼š\nè¾“å…¥æ˜¯ä¸€ä¸ªSRTæ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼ŒåŒ…å«å¤šä¸ªæ¡ç›®ï¼Œæ¯ä¸ªæ¡ç›®ç”±ç¼–å·ã€æ—¶é—´æˆ³ï¼ˆæ ¼å¼å¦‚ï¼š00:00:01,000 --> 00:00:04,000ï¼‰å’Œæ–‡æœ¬å†…å®¹ç»„æˆã€‚\nè§£æSRTæ–‡ä»¶ï¼Œæå–æ‰€æœ‰æ¡ç›®çš„æ—¶é—´æˆ³å’Œå¯¹åº”æ–‡æœ¬ã€‚å¿½ç•¥æ— å…³æ ¼å¼ï¼ˆå¦‚ç©ºç™½è¡Œï¼‰ã€‚\n\nçŸ¥è¯†ç‚¹æå–ä¸åˆ†æï¼š\nåˆ†ææ¯ä¸ªæ—¶é—´æˆ³å¯¹åº”çš„æ–‡æœ¬å†…å®¹ï¼Œè¯†åˆ«å…³é”®çŸ¥è¯†ç‚¹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š\næ ¸å¿ƒæ¦‚å¿µã€å®šä¹‰æˆ–ç†è®º\né‡è¦äº‹å®ã€æ•°æ®æˆ–ä¾‹å­\næ­¥éª¤ã€æµç¨‹æˆ–æ€»ç»“æ€§é™ˆè¿°\nä»»ä½•é‡å¤æˆ–å¼ºè°ƒçš„å†…å®¹\nä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æç‚¼çŸ¥è¯†ç‚¹ï¼Œé¿å…å†—ä½™ï¼Œèšç„¦äºç”¨æˆ·å¯èƒ½éœ€è¦çš„å¤ä¹ é‡ç‚¹ã€‚\n\nMarkdownæ ¼å¼ç»„ç»‡ï¼š\nä½¿ç”¨æ ‡å‡†çš„Markdownè¯­æ³•ç»„ç»‡å†…å®¹ï¼š\nä½¿ç”¨#ã€##ã€###ç­‰æ ‡é¢˜çº§åˆ«åˆ›å»ºæ¸…æ™°çš„ç»“æ„å±‚æ¬¡\nä½¿ç”¨åˆ—è¡¨ï¼ˆ-æˆ–1.ï¼‰å‘ˆç°çŸ¥è¯†ç‚¹\nä½¿ç”¨è¡¨æ ¼ï¼ˆå¦‚éœ€è¦ï¼‰æ•´ç†ç»“æ„åŒ–ä¿¡æ¯\nä½¿ç”¨ä»£ç å—ï¼ˆå¦‚éœ€è¦ï¼‰å±•ç¤ºæŠ€æœ¯å†…å®¹\nä½¿ç”¨ç²—ä½“æˆ–æ–œä½“å¼ºè°ƒé‡ç‚¹\n\næ—¶é—´æˆ³æ ‡è®°ï¼š\nåœ¨æ¯ä¸ªçŸ¥è¯†ç‚¹æ—è¾¹æ˜ç¡®æ ‡è®°å¯¹åº”çš„SRTæ—¶é—´æˆ³ï¼Œæ ¼å¼ä¸ºï¼š[å¼€å§‹æ—¶é—´ --> ç»“æŸæ—¶é—´]\nå¦‚æœå¤šä¸ªæ—¶é—´æˆ³å¯¹åº”åŒä¸€çŸ¥è¯†ç‚¹ï¼Œå¯åˆå¹¶æ ‡è®°æˆ–åˆ†åˆ«æ³¨æ˜ã€‚\n\nè¾“å‡ºè¦æ±‚ï¼š\nå¯ä»¥æ··åˆå…¶ä»–è¯­è¨€ï¼Œä½†ä¸»ä½“ç”¨ä¸­æ–‡è¾“å‡ºã€‚\nç”Ÿæˆå®Œæ•´çš„Markdownæ–‡æ¡£ï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š\næ–‡æ¡£æ ‡é¢˜å’Œç®€è¦è¯´æ˜\næŒ‰ä¸»é¢˜æˆ–æ—¶é—´é¡ºåºç»„ç»‡çš„çŸ¥è¯†ç‚¹æ€»ç»“\nç¡®ä¿è¾“å‡ºç®€æ´ã€å‡†ç¡®ï¼Œè¦†ç›–æ‰€æœ‰é‡è¦å†…å®¹ã€‚\n\nç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼š\n<MARKDOWN>\n### åŸºç¡€ç†è®º\n- **çŸ¥è¯†ç‚¹1**ï¼šç®€è¦æè¿°æ¦‚å¿µå†…å®¹ [`00:00:01,000 --> 00:00:04,000`]\n- **çŸ¥è¯†ç‚¹2**ï¼šå¦ä¸€é‡è¦æ¦‚å¿µè¯´æ˜ [`00:00:05,000 --> 00:00:08,000`]\n### å…³é”®æŠ€æœ¯\n1. **æŠ€æœ¯è¦ç‚¹1**ï¼šè¯¦ç»†è¯´æ˜ [`00:00:10,000 --> 00:00:15,000`]\n2. **æŠ€æœ¯è¦ç‚¹2**ï¼šè¡¥å……è¯´æ˜ [`00:00:16,000 --> 00:00:20,000`]",
    "SRTè½¬æ¢PotPlayerä¹¦ç­¾Json": "ä½ æ˜¯ä¸€ä¸ªAIå­¦ä¹ åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·æä¾›çš„SRTå­—å¹•æ–‡ä»¶ç”Ÿæˆç»“æ„åŒ–çš„JSONæ ¼å¼çŸ¥è¯†ç‚¹ä¹¦ç­¾ã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¤„ç†è¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªç¬¦åˆæŒ‡å®šJSONæ ¼å¼çš„çŸ¥è¯†ç‚¹ä¹¦ç­¾æ–‡ä»¶ï¼š\n\nè¾“å…¥è§£æ\n- è¾“å…¥æ˜¯ä¸€ä¸ªSRTæ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼ŒåŒ…å«å¤šä¸ªæ¡ç›®\n- æ¯ä¸ªæ¡ç›®ç”±ç¼–å·ã€æ—¶é—´æˆ³ï¼ˆæ ¼å¼å¦‚ï¼š00:00:01,000 --> 00:00:04,000ï¼‰å’Œæ–‡æœ¬å†…å®¹ç»„æˆ\n- è§£æSRTæ–‡ä»¶ï¼Œæå–æ‰€æœ‰æ¡ç›®çš„æ—¶é—´æˆ³å’Œå¯¹åº”æ–‡æœ¬ï¼Œå¿½ç•¥æ— å…³æ ¼å¼ï¼ˆå¦‚ç©ºç™½è¡Œï¼‰\n\nçŸ¥è¯†ç‚¹æå–ä¸åˆ†æ\nåˆ†ææ¯ä¸ªæ—¶é—´æˆ³å¯¹åº”çš„æ–‡æœ¬å†…å®¹ï¼Œè¯†åˆ«å…³é”®çŸ¥è¯†ç‚¹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š\n- æ ¸å¿ƒæ¦‚å¿µã€å®šä¹‰æˆ–ç†è®º\n- é‡è¦äº‹å®ã€æ•°æ®æˆ–ä¾‹å­\n- æ­¥éª¤ã€æµç¨‹æˆ–æ€»ç»“æ€§é™ˆè¿°\n- ä»»ä½•é‡å¤æˆ–å¼ºè°ƒçš„å†…å®¹\n- æŠ€æœ¯è¦ç‚¹æˆ–æ“ä½œè¯´æ˜\n\nä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æç‚¼çŸ¥è¯†ç‚¹ï¼Œè¦æ±‚ï¼š\n- é¿å…å†—ä½™ï¼Œèšç„¦äºç”¨æˆ·å¯èƒ½éœ€è¦çš„å¤ä¹ é‡ç‚¹\n- æ¯ä¸ªçŸ¥è¯†ç‚¹åç§°åº”ç®€æ´æ˜äº†ï¼Œé•¿åº¦é€‚ä¸­\n- åˆå¹¶ç›¸é‚»æ—¶é—´æ®µçš„ç›¸å…³å†…å®¹å½¢æˆå®Œæ•´çŸ¥è¯†ç‚¹\n- æŒ‰æ—¶é—´é¡ºåºç»„ç»‡çŸ¥è¯†ç‚¹\n\næ—¶é—´æˆ³éªŒè¯ä¸è¾¹ç•Œæ£€æŸ¥\n- ä¸¥æ ¼åŸºäºSRTæ–‡ä»¶ä¸­å®é™…å­˜åœ¨çš„æ—¶é—´æˆ³\n- åªä½¿ç”¨å­—å¹•æ¡ç›®çš„å¼€å§‹æ—¶é—´ä½œä¸ºçŸ¥è¯†ç‚¹æ—¶é—´æ ‡è®°\n- ç¡®ä¿æ‰€æœ‰æ—¶é—´æ ‡è®°éƒ½åœ¨SRTæ–‡ä»¶çš„æ—¶é—´èŒƒå›´å†…\n- ä¸ç”Ÿæˆè¶…å‡ºå®é™…å­—å¹•å†…å®¹èŒƒå›´çš„æ—¶é—´æˆ³\n- å¦‚æœSRTæ–‡ä»¶æœ‰æ˜ç¡®çš„ç»“æŸæ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰æ—¶é—´æ ‡è®°ä¸è¶…è¿‡è¯¥æ—¶é—´\n\nJSONæ ¼å¼è¦æ±‚\nè¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONæ ¼å¼ï¼š\n{\n  \"bookmarks_count\": ä¹¦ç­¾æ€»æ•°,\n  \"bookmarks\": [\n    {\n      \"index\": \"åºå·\",\n      \"name\": \"çŸ¥è¯†ç‚¹åç§°\",\n      \"time_formatted\": \"HH:MM:SS.mmm\"\n    }\n  ]\n}\n\næ—¶é—´æ ¼å¼å¤„ç†\n- å°†SRTæ—¶é—´æˆ³æ ¼å¼ï¼ˆ00:00:01,000ï¼‰è½¬æ¢ä¸ºç›®æ ‡æ ¼å¼ï¼ˆ00:00:01.000ï¼‰\n- ä½¿ç”¨å¼€å§‹æ—¶é—´ä½œä¸ºè¯¥çŸ¥è¯†ç‚¹çš„æ—¶é—´æ ‡è®°\n- æ—¶é—´æ ¼å¼ï¼šHH:MM:SS.mmmï¼ˆå°æ—¶:åˆ†é’Ÿ:ç§’.æ¯«ç§’ï¼‰\n\nè¾“å‡ºè¦æ±‚\n- è¾“å‡ºå¿…é¡»æ˜¯å®Œæ•´ã€æœ‰æ•ˆçš„JSONæ ¼å¼\n- æ€»ç»“çš„çŸ¥è¯†ç‚¹å¿…é¡»å‡†ç¡®å¯¹åº”SRTæ–‡ä»¶çš„æ—¶é—´æˆ³\n- æ¯ä¸ªçŸ¥è¯†ç‚¹æ¡ç›®å¿…é¡»ä¸å…¶srtå†…å®¹æ¥æºçš„æ—¶é—´æˆ³å¯¹åº”\n- ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ä¹¦ç­¾æ¡ç›®ï¼Œä¸¥ç¦è°ƒæ¢é¡ºåº\n- ç´¢å¼•ä»\"0\"å¼€å§‹è¿ç»­ç¼–å·\n- çŸ¥è¯†ç‚¹åç§°ä½¿ç”¨ä¸­æ–‡ï¼Œç¡®ä¿å‡†ç¡®è¡¨è¾¾å†…å®¹\n- è¦†ç›–æ‰€æœ‰é‡è¦çŸ¥è¯†ç‚¹ï¼Œé¿å…é—æ¼å…³é”®ä¿¡æ¯\n- ä¸è¦åŒ…å«```jsonæ ‡è®°ï¼Œç›´æ¥è¾“å‡ºçº¯JSONå†…å®¹\n- ç¡®ä¿æ‰€æœ‰æ—¶é—´æˆ³éƒ½åœ¨SRTæ–‡ä»¶çš„å®é™…æ—¶é—´èŒƒå›´å†…\n- ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šè¯´æ˜\n\nç¤ºä¾‹è¾“å‡º\n{\n  \"bookmarks_count\": 2,\n  \"bookmarks\": [\n    {\n    \"index\": \"0\",\n    \"name\": \"ClayBuildUpBrushå·¥å…·ä»‹ç»\",\n    \"time_formatted\": \"00:06:34.415\"\n    },\n    {\n    \"index\": \"1\",\n    \"name\": \"é€šè¿‡Tool â†’ Load Tool from Projectå¯ä»¥ä»é¡¹ç›®ä¸­å•ç‹¬åŠ è½½å·¥å…·\",\n    \"time_formatted\": \"00:07:00.427\"\n    }\n  ]\n}\n\nå¤„ç†æµç¨‹\n1. è§£æSRTæ–‡ä»¶ï¼Œæå–æ—¶é—´æˆ³å’Œæ–‡æœ¬å†…å®¹\n2. åˆ†ææ–‡æœ¬å†…å®¹ï¼Œè¯†åˆ«å’Œæç‚¼å…³é”®çŸ¥è¯†ç‚¹\n3. åˆå¹¶ç›¸å…³æ—¶é—´æ®µçš„å†…å®¹å½¢æˆå®Œæ•´çŸ¥è¯†ç‚¹\n4. ä¸ºæ¯ä¸ªçŸ¥è¯†ç‚¹ç”Ÿæˆç®€æ´çš„åç§°\n5. éªŒè¯æ—¶é—´æˆ³ä¸è¶…å‡ºSRTæ–‡ä»¶èŒƒå›´\n6. ä¸¥æ ¼æŒ‰æ—¶é—´é¡ºåºç»„ç»‡å¹¶ç¼–å·\n7. è¾“å‡ºç¬¦åˆæ ¼å¼è¦æ±‚çš„JSON\n\nè¯·ç¡®ä¿è¾“å‡ºçš„JSONæ–‡ä»¶å¯ä»¥ç›´æ¥ç”¨äºåç»­å¤„ç†ï¼Œæ ¼å¼æ­£ç¡®ä¸”å†…å®¹å®Œæ•´ã€‚",
}

# AIæä¾›è€…é…ç½®
DEFAULT_PROVIDERS = {
    "é˜¿é‡Œé€šä¹‰": {
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "models": {
            "é€šä¹‰åƒé—®Flash": "qwen-flash",
            "é€šä¹‰åƒé—®Plus": "qwen-plus",
            "é€šä¹‰åƒé—®3Max": "qwen3-max",
            "é€šä¹‰åƒé—®Turbo": "qwen-turbo"
        }
    },
    "DeepSeek": {
        "base_url": "https://api.deepseek.com",
        "models": {
            "DeepSeek Chat": "deepseek-chat"
        }
    },
    "æ™ºè°±AI": {
        "base_url": "https://open.bigmodel.cn/api/paas/v3/model-api",
        "models": {
            "æ™ºè°±ChatGLM Turbo": "chatglm_turbo",
            "æ™ºè°±ChatGLM Pro": "chatglm_pro",
            "æ™ºè°±ChatGLM Std": "chatglm_std"
        }
    },
    "ç¡…åŸºæµåŠ¨": {
        "base_url": "https://api.siliconflow.cn/v1",
        "models": {
            "Hunyuan-A13B-Instruct": "tencent/Hunyuan-A13B-Instruct",
            "Qwen3-Next-80B-A3B-Instruct": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "Qwen3-Omni-30B-A3B-Thinking": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
            "Qwen3-Omni-30B-A3B-Instruct": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
            "DeepSeek-V3": "deepseek-ai/DeepSeek-V3"
        }
    }
}

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception:
        pass
    return {'custom_prompts': {}, 'providers': {}, 'provider_keys': {}}

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open('config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

def load_custom_prompts():
    """åŠ è½½ä¿å­˜çš„è‡ªå®šä¹‰prompts"""
    config = load_config()
    return config.get('custom_prompts', {})

def save_custom_prompts(prompts):
    """ä¿å­˜è‡ªå®šä¹‰prompts"""
    config = load_config()
    config['custom_prompts'] = prompts
    save_config(config)

def scan_files_by_extension(directory, extensions):
    """æ‰«æç›®å½•åŠå…¶å­ç›®å½•ä¸­æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶
    Args:
        directory: ç›®å½•è·¯å¾„
        extensions: æ‰©å±•ååˆ—è¡¨ï¼Œå¦‚ ['txt', 'srt']ï¼ˆä¸åŒ…å«ç‚¹ï¼‰
    """
    matched_files = []
    extensions = [ext.lower() if ext.startswith('.') else f'.{ext.lower()}' for ext in extensions]
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in extensions:
                matched_files.append(os.path.join(root, file))
    return matched_files

def process_file(file_path, client, system_prompt, model_id, temperature=0.7, output_format='txt'):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶è¿”å›AIå“åº”
    Args:
        file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
        client: OpenAIå®¢æˆ·ç«¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        model_id: æ¨¡å‹ID
        temperature: æ¸©åº¦å‚æ•°
        output_format: è¾“å‡ºæ ¼å¼(txt, jsonç­‰)
    Returns:
        å¤„ç†ç»“æœï¼ˆæ ¹æ®output_formatè¿”å›ç›¸åº”æ ¼å¼ï¼‰
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': content}
            ],
            temperature=temperature,
            stream=False
        )
        
        response_content = completion.choices[0].message.content
        
        # å¦‚æœè¾“å‡ºæ ¼å¼æ˜¯jsonï¼Œåˆ™å°†ç»“æœåŒ…è£…æˆJSONæ ¼å¼
        if output_format.lower() == 'json':
            result_data = {
                'source_file': file_path,
                'original_content_length': len(content),
                'system_prompt': system_prompt,
                'model': model_id,
                'temperature': temperature,
                'response': response_content
            }
            return json.dumps(result_data, ensure_ascii=False, indent=2)
        
        return response_content
    except Exception as e:
        error_msg = f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        if output_format.lower() == 'json':
            error_data = {
                'source_file': file_path,
                'error': error_msg
            }
            return json.dumps(error_data, ensure_ascii=False, indent=2)
        return error_msg

def save_response(file_path, response, output_format='md'):
    """å°†å“åº”ä¿å­˜ä¸ºæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶
    Args:
        file_path: åŸæ–‡ä»¶è·¯å¾„
        response: AIå“åº”å†…å®¹
        output_format: è¾“å‡ºæ–‡ä»¶æ ¼å¼ï¼Œå¦‚ 'md', 'txt', 'srt' ç­‰ï¼ˆä¸åŒ…å«ç‚¹ï¼‰
    """
    # è·å–åŸæ–‡ä»¶æ‰€åœ¨ç›®å½•å’Œæ–‡ä»¶å
    directory = os.path.dirname(file_path)
    filename = os.path.basename(file_path)
    
    # è·å–åŸæ–‡ä»¶çš„æ‰©å±•åï¼ˆå¦‚ .txt, .srt ç­‰ï¼‰
    file_ext = os.path.splitext(filename)[1]
    file_name_without_ext = os.path.splitext(filename)[0]
    
    # å¦‚æœæ²¡æœ‰åŒ…å«ç‚¹ï¼Œè‡ªåŠ¨æ·»åŠ 
    if not output_format.startswith('.'):
        output_format = f'.{output_format}'
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_filename = file_name_without_ext + output_format
    output_path = os.path.join(directory, output_filename)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(response)
    
    return output_path

def load_providers():
    """åŠ è½½AIæä¾›è€…é…ç½®"""
    config = load_config()
    providers = config.get('providers', {})
    # åˆå¹¶é»˜è®¤æä¾›è€…å’Œè‡ªå®šä¹‰æä¾›è€…
    all_providers = {**DEFAULT_PROVIDERS, **providers}
    return all_providers

def save_provider(name, base_url, models):
    """ä¿å­˜è‡ªå®šä¹‰AIæä¾›è€…"""
    config = load_config()
    if 'providers' not in config:
        config['providers'] = {}
    
    config['providers'][name] = {
        "base_url": base_url,
        "models": models
    }
    save_config(config)

def get_provider_api_key(provider_name):
    """è·å–æä¾›è€…çš„API key"""
    config = load_config()
    provider_keys = config.get('provider_keys', {})
    return provider_keys.get(provider_name, '')

def save_provider_api_key(provider_name, api_key):
    """ä¿å­˜æä¾›è€…çš„API key"""
    config = load_config()
    if 'provider_keys' not in config:
        config['provider_keys'] = {}
    config['provider_keys'][provider_name] = api_key
    save_config(config)

def get_model_temperature():
    """è·å–æ¨¡å‹æ¸©åº¦è®¾ç½®"""
    config = load_config()
    model_settings = config.get('model_settings', {})
    return model_settings.get('temperature', 0.7)

def save_model_temperature(temperature):
    """ä¿å­˜æ¨¡å‹æ¸©åº¦è®¾ç½®"""
    config = load_config()
    if 'model_settings' not in config:
        config['model_settings'] = {}
    config['model_settings']['temperature'] = temperature
    save_config(config)

def main():
    st.set_page_config(page_title="AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹", layout="wide")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.title("âš™ï¸ é…ç½®")
        
        # AIæä¾›è€…é…ç½®
        st.subheader("AIæä¾›è€…è®¾ç½®")
        
        # åŠ è½½æ‰€æœ‰æä¾›è€…
        all_providers = load_providers()
        selected_provider = st.selectbox(
            "é€‰æ‹©AIæä¾›è€…",
            options=list(all_providers.keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæœåŠ¡æä¾›å•†"
        )
        
        # é€‰æ‹©æ¨¡å‹
        provider_config = all_providers[selected_provider]
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=list(provider_config["models"].keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
        )
        
        # API Keyè®¾ç½®
        current_api_key = get_provider_api_key(selected_provider)
        api_key = st.text_input(
            f"{selected_provider} API Key", 
            value=current_api_key,
            type="password",
            help=f"è¾“å…¥{selected_provider}çš„APIå¯†é’¥"
        )
        
        if api_key != current_api_key:
            save_provider_api_key(selected_provider, api_key)
            st.success("API Keyå·²ä¿å­˜")
        
        # æ¨¡å‹æ¸©åº¦è®¾ç½®
        st.divider()
        st.subheader("æ¨¡å‹å‚æ•°è®¾ç½®")
        
        current_temperature = get_model_temperature()
        temperature = st.slider(
            "æ¨¡å‹æ¸©åº¦",
            min_value=0.0,
            max_value=2.0,
            value=current_temperature,
            step=0.1,
            help="æ¸©åº¦å€¼æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ã€‚0è¡¨ç¤ºç¡®å®šæ€§è¾“å‡ºï¼ˆæœ€ç¨³å®šï¼‰ï¼Œ2è¡¨ç¤ºé«˜éšæœºæ€§ï¼ˆæœ€åˆ›æ„ï¼‰ã€‚å»ºè®®å€¼ï¼š\n- æ€»ç»“ï¼š0.3-0.5ï¼ˆè¾ƒä½ï¼‰\n- åˆ›æ„å†™ä½œï¼š1.0-1.5ï¼ˆè¾ƒé«˜ï¼‰\n- å¸¸è§„ä»»åŠ¡ï¼š0.7-0.8ï¼ˆé€‚ä¸­ï¼‰"
        )
        
        if temperature != current_temperature:
            save_model_temperature(temperature)
            st.success(f"æ¸©åº¦å·²è®¾ç½®ä¸º {temperature}")
        
        # æ–‡ä»¶ç±»å‹é€‰æ‹©
        st.divider()
        st.subheader("æ–‡ä»¶ç±»å‹é€‰æ‹©")
        
        file_type_option = st.radio(
            "é€‰æ‹©å¤„ç†æ–¹å¼",
            options=["é¢„è®¾ç±»å‹", "è‡ªå®šä¹‰ç±»å‹"],
            horizontal=True,
            help="é€‰æ‹©ä½¿ç”¨é¢„è®¾çš„æ–‡ä»¶ç±»å‹æˆ–è‡ªå®šä¹‰",
            key="file_type_option"
        )
        
        if file_type_option == "é¢„è®¾ç±»å‹":
            selected_file_types = st.multiselect(
                "é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶ç±»å‹",
                options=["txt", "srt", "md", "log"],
                default=["txt"],
                help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ç±»å‹",
                key="preset_file_types"
            )
        else:
            custom_types_input = st.text_input(
                "è¾“å…¥æ–‡ä»¶æ‰©å±•åï¼ˆé€—å·åˆ†éš”ï¼‰",
                value="txt,srt",
                placeholder="ä¾‹ï¼štxt,srt,md,log",
                help="è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•åï¼Œç”¨é€—å·åˆ†éš”",
                key="custom_file_types"
            )
            selected_file_types = [t.strip() for t in custom_types_input.split(',') if t.strip()]
        
        if not selected_file_types:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ç±»å‹")
            selected_file_types = ["txt"]  # é»˜è®¤å€¼
        
        # è¾“å‡ºæ ¼å¼é€‰æ‹©
        st.divider()
        st.subheader("è¾“å‡ºæ ¼å¼è®¾ç½®")
        
        output_format_option = st.radio(
            "é€‰æ‹©è¾“å‡ºæ ¼å¼æ–¹å¼",
            options=["é¢„è®¾æ ¼å¼", "è‡ªå®šä¹‰æ ¼å¼"],
            horizontal=True,
            help="é€‰æ‹©ä½¿ç”¨é¢„è®¾çš„è¾“å‡ºæ ¼å¼æˆ–è‡ªå®šä¹‰",
            key="output_format_option"
        )
        
        if output_format_option == "é¢„è®¾æ ¼å¼":
            selected_output_format = st.selectbox(
                "é€‰æ‹©è¾“å‡ºæ–‡ä»¶æ ¼å¼",
                options=["md", "txt", "srt", "log", "json"],
                index=0,
                help="æ‰€æœ‰å¤„ç†ç»“æœéƒ½å°†ä¿å­˜ä¸ºé€‰ä¸­çš„æ ¼å¼",
                key="preset_output_format"
            )
        else:
            custom_output_format = st.text_input(
                "è¾“å…¥è¾“å‡ºæ–‡ä»¶æ‰©å±•å",
                value="md",
                placeholder="ä¾‹ï¼šmd, txt, srt",
                help="è¾“å…¥è¾“å‡ºæ–‡ä»¶çš„æ‰©å±•åï¼ˆä¸åŒ…å«ç‚¹ï¼‰",
                key="custom_output_format"
            )
            selected_output_format = custom_output_format.strip().lstrip('.')
        
        if not selected_output_format:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„è¾“å‡ºæ ¼å¼")
            selected_output_format = "md"  # é»˜è®¤å€¼
        
        st.markdown("---")

        # æ·»åŠ æ–°çš„æä¾›è€…
        with st.expander("æ·»åŠ æ–°çš„AIæä¾›è€…"):
            new_provider_name = st.text_input("æä¾›è€…åç§°")
            new_provider_base_url = st.text_input("Base URL")
            
            # åˆå§‹åŒ–session state
            if 'new_models' not in st.session_state:
                st.session_state.new_models = {}
            
            # æ˜¾ç¤ºå½“å‰å·²æ·»åŠ çš„æ¨¡å‹
            if st.session_state.new_models:
                st.write("å·²æ·»åŠ çš„æ¨¡å‹ï¼š")
                for model_name, model_id in st.session_state.new_models.items():
                    st.write(f"- {model_name}: {model_id}")
            
            # åŠ¨æ€æ¨¡å‹é…ç½®
            st.subheader("é…ç½®æ¨¡å‹")
            
            col1, col2 = st.columns(2)
            with col1:
                model_name = st.text_input("æ¨¡å‹æ˜¾ç¤ºåç§°")
            with col2:
                model_id = st.text_input("æ¨¡å‹ID")
            
            if st.button("æ·»åŠ æ¨¡å‹", key="add_model_btn") and model_name and model_id:
                st.session_state.new_models[model_name] = model_id
                st.success(f"å·²æ·»åŠ æ¨¡å‹: {model_name}")
                st.rerun()
            
            # æ¸…é™¤æ¨¡å‹æŒ‰é’®
            if st.session_state.new_models and st.button("æ¸…é™¤æ‰€æœ‰æ¨¡å‹", type="secondary", key="clear_models_btn"):
                st.session_state.new_models = {}
                st.rerun()
            
            # ä¿å­˜æä¾›è€…æŒ‰é’®
            if st.button("ä¿å­˜æä¾›è€…", type="primary", key="save_provider_btn"):
                if new_provider_name and new_provider_base_url and st.session_state.new_models:
                    save_provider(new_provider_name, new_provider_base_url, st.session_state.new_models)
                    # æ¸…ç©ºsession state
                    st.session_state.new_models = {}
                    st.success("ä¿å­˜æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„æä¾›è€…ä¿¡æ¯å¹¶è‡³å°‘æ·»åŠ ä¸€ä¸ªæ¨¡å‹")
        
        st.markdown("---")
        
        # Promptç®¡ç†
        st.subheader("Promptç®¡ç†")
        
        # åŠ è½½è‡ªå®šä¹‰prompts
        custom_prompts = load_custom_prompts()
        all_prompts = {**DEFAULT_PROMPTS, **custom_prompts}
        
        # Prompté€‰æ‹©
        selected_prompt_name = st.selectbox(
            "é€‰æ‹©System Prompt",
            options=list(all_prompts.keys()),
            help="é€‰æ‹©é¢„è®¾çš„promptæˆ–æ·»åŠ è‡ªå®šä¹‰prompt"
        )
        selected_prompt = all_prompts[selected_prompt_name]
        
        with st.expander("æŸ¥çœ‹å½“å‰Promptå†…å®¹"):
            st.text_area(
                "å½“å‰System Prompt",
                value=selected_prompt,
                height=100,
                disabled=True
            )
        
        # åˆ é™¤è‡ªå®šä¹‰promptçš„æŒ‰é’®
        if selected_prompt_name in custom_prompts:
            if st.button(f"ğŸ—‘ï¸ åˆ é™¤ '{selected_prompt_name}'", type="secondary", key=f"delete_prompt_{selected_prompt_name}"):
                del custom_prompts[selected_prompt_name]
                save_custom_prompts(custom_prompts)
                st.success(f"å·²åˆ é™¤ '{selected_prompt_name}'")
                st.rerun()
        
        # æ·»åŠ æ–°çš„prompt
        with st.expander("æ·»åŠ æ–°çš„Prompt"):
            new_prompt_name = st.text_input(
                "Promptåç§°",
                help="ä¸ºæ–°çš„promptèµ·ä¸€ä¸ªåå­—"
            )
            new_prompt_content = st.text_area(
                "Promptå†…å®¹",
                height=100,
                help="è¾“å…¥promptçš„å…·ä½“å†…å®¹"
            )
            
            if st.button("ğŸ’¾ ä¿å­˜", type="primary", key="save_prompt_btn"):
                if new_prompt_name and new_prompt_content:
                    if new_prompt_name in DEFAULT_PROMPTS:
                        st.error("ä¸èƒ½è¦†ç›–é¢„è®¾çš„Prompt")
                    else:
                        custom_prompts[new_prompt_name] = new_prompt_content
                        save_custom_prompts(custom_prompts)
                        st.success("ä¿å­˜æˆåŠŸï¼")
                        st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„Promptä¿¡æ¯")
    
    # ä¸»ç•Œé¢
    st.title("ğŸ“ AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹")
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    1. åœ¨ä¾§è¾¹æ é…ç½®API Keyå’Œé€‰æ‹©åˆé€‚çš„Prompt
    2. è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶ç›®å½•è·¯å¾„
    3. ç‚¹å‡»å¼€å§‹å¤„ç†
    
    ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š
    - æ‰«æç›®å½•ä¸‹æ‰€æœ‰txtæ–‡ä»¶
    - ä½¿ç”¨AIå¤„ç†æ–‡ä»¶å†…å®¹
    - å°†ç»“æœä¿å­˜ä¸ºåŒåçš„mdæ–‡ä»¶
    """)
    
    # ç›®å½•é€‰æ‹©
    directory = st.text_input(
        "ğŸ“ å¤„ç†ç›®å½•",
        help="è¾“å…¥è¦å¤„ç†çš„ç›®å½•çš„å®Œæ•´è·¯å¾„ï¼Œç³»ç»Ÿå°†å¤„ç†è¯¥ç›®å½•ä¸‹æ‰€æœ‰çš„txtæ–‡ä»¶"
    )
    
    col1, col2 = st.columns([1, 3])
    with col1:
        start_button = st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", key="start_process_btn", disabled=not (api_key and directory))
    
    if not api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®API Key")
    if not directory:
        st.warning("âš ï¸ è¯·è¾“å…¥è¦å¤„ç†çš„ç›®å½•è·¯å¾„")
    
    if start_button:
        try:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–AIå®¢æˆ·ç«¯..."):
                client = OpenAI(
                    api_key=api_key,
                    base_url=all_providers[selected_provider]["base_url"]
                )
            
            # è·å–é€‰ä¸­çš„æ¨¡å‹ID
            model_id = all_providers[selected_provider]["models"][selected_model]
            
            # è·å–æ¸©åº¦è®¾ç½®
            temperature = get_model_temperature()
            
            # æ‰«ææ–‡ä»¶
            with st.spinner("æ­£åœ¨æ‰«ææ–‡ä»¶..."):
                matched_files = scan_files_by_extension(directory, selected_file_types)
            
            if not matched_files:
                file_types_str = ", ".join(selected_file_types)
                st.warning(f"ğŸ“‚ æœªæ‰¾åˆ°æŒ‡å®šç±»å‹çš„æ–‡ä»¶ï¼ˆ{file_types_str}ï¼‰")
                return
            
            file_types_str = ", ".join(selected_file_types)
            st.info(f"æ‰¾åˆ° {len(matched_files)} ä¸ªæ–‡ä»¶ ({file_types_str})ï¼Œè¾“å‡ºæ ¼å¼: .{selected_output_format}ï¼Œä½¿ç”¨æ¸©åº¦å€¼: {temperature}")
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ›å»ºä¸€ä¸ªåŒºåŸŸæ˜¾ç¤ºå¤„ç†ç»“æœï¼ˆåŒ…å«çŠ¶æ€ï¼‰
            results_area = st.empty()
            processed_files = []
            skipped_count = 0

            for i, file_path in enumerate(matched_files):
                status_text.text(f"â³ æ­£åœ¨å¤„ç†: {file_path}")

                # ç”Ÿæˆå¯¹åº”çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                file_dir = os.path.dirname(file_path)
                file_name = os.path.basename(file_path)
                file_name_without_ext = os.path.splitext(file_name)[0]
                output_filename = file_name_without_ext + f'.{selected_output_format}'
                output_path = os.path.join(file_dir, output_filename)

                # å¦‚æœå·²å­˜åœ¨åŒåè¾“å‡ºæ–‡ä»¶ï¼Œåˆ™è·³è¿‡å¤„ç†
                if os.path.exists(output_path):
                    skipped_count += 1
                    processed_files.append((file_path, output_path, 'è·³è¿‡-å·²å­˜åœ¨'))
                else:
                    # å¤„ç†æ–‡ä»¶
                    response = process_file(file_path, client, all_prompts[selected_prompt_name], model_id, temperature, selected_output_format)

                    # ä¿å­˜å“åº”ï¼Œä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºæ ¼å¼
                    output_path = save_response(file_path, response, selected_output_format)
                    processed_files.append((file_path, output_path, 'å·²å¤„ç†'))

                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(matched_files)
                progress_bar.progress(progress)

                # æ›´æ–°å¤„ç†ç»“æœæ˜¾ç¤º
                results_df = pd.DataFrame(
                    processed_files,
                    columns=['æºæ–‡ä»¶', 'ç»“æœæ–‡ä»¶', 'çŠ¶æ€']
                )
                results_area.dataframe(
                    results_df,
                    hide_index=True,
                    use_container_width=True
                )
            
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")
            st.success(f"å®Œæˆï¼šå…±æ‰«æ {len(matched_files)} ä¸ªæ–‡ä»¶ï¼Œå·²å¤„ç† {len(matched_files)-skipped_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ªï¼ˆå·²å­˜åœ¨åŒåmdï¼‰")
            
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    main() 