import streamlit as st
import os
import json
from openai import OpenAI
from pathlib import Path
import pandas as pd

# é¢„è®¾çš„system prompts
DEFAULT_PROMPTS = {
    "æ–‡ç« æ€»ç»“": "You are an expert at summarizing text. Please provide a concise summary in Chinese.",
    "ä»£ç åˆ†æ": "You are a code review expert. Please analyze the code and provide suggestions.",
    "é€šç”¨åŠ©æ‰‹": "You are a helpful assistant.",
    "æ–‡æ¡£è½¬æ–‡ç¨¿": "å°†ç”¨æˆ·è¾“å…¥çš„å†…å®¹è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œè¦æ±‚æœ€å¤§ç¨‹åº¦çš„ä¿ç•™ä¿¡æ¯å®Œæ•´ï¼ŒåŒæ—¶è½¬æ¢åçš„æ–‡æœ¬è¦æ±‚ä¾¿äºæœ—è¯»å’Œè®°å¿†ã€‚è½¬æ¢åçš„æ–‡æœ¬ä¸ç”¨äºé˜…è¯»ï¼Œåªç”¨äºå¬è¯»ã€‚",
}

# AIæä¾›è€…é…ç½®
DEFAULT_PROVIDERS = {
    "é˜¿é‡Œé€šä¹‰": {
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "models": {
            "é€šä¹‰åƒé—®Plus": "qwen-plus",
            "é€šä¹‰åƒé—®Turbo": "qwen-turbo",
            "é€šä¹‰åƒé—®Max": "qwen-max"
        }
    },
    "DeepSeek": {
        "base_url": "https://api.deepseek.com",
        "models": {
            "DeepSeek Chat": "deepseek-chat"
        }
    },
    "ç™¾åº¦æ–‡å¿ƒ": {
        "base_url": "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat",
        "models": {
            "æ–‡å¿ƒä¸€è¨€4.0": "ernie-bot-4",
            "æ–‡å¿ƒä¸€è¨€Turbo": "ernie-bot-turbo",
            "æ–‡å¿ƒä¸€è¨€": "ernie-bot"
        }
    },
    "æ™ºè°±AI": {
        "base_url": "https://open.bigmodel.cn/api/paas/v3/model-api",
        "models": {
            "æ™ºè°±ChatGLM Turbo": "chatglm_turbo",
            "æ™ºè°±ChatGLM Pro": "chatglm_pro",
            "æ™ºè°±ChatGLM Std": "chatglm_std"
        }
    },
    "ç¡…åŸºæµåŠ¨": {
        "base_url": "https://api.siliconflow.cn/v1",
        "models": {
            "Qwen2.5-72B-Instruct": "Qwen/Qwen2.5-72B-Instruct",
            "QwQ-32B-Preview": "Qwen/QwQ-32B-Preview",
            "QVQ-72B-Preview": "Qwen/QVQ-72B-Preview",
            "Qwen2.5-Coder-32B-Instruct": "Qwen/Qwen2.5-Coder-32B-Instruct",
            "DeepSeek-V2.5": "deepseek-ai/DeepSeek-V2.5"
        }
    }
}

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception:
        pass
    return {'custom_prompts': {}, 'providers': {}, 'provider_keys': {}}

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open('config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

def load_custom_prompts():
    """åŠ è½½ä¿å­˜çš„è‡ªå®šä¹‰prompts"""
    config = load_config()
    return config.get('custom_prompts', {})

def save_custom_prompts(prompts):
    """ä¿å­˜è‡ªå®šä¹‰prompts"""
    config = load_config()
    config['custom_prompts'] = prompts
    save_config(config)

def scan_txt_files(directory):
    """æ‰«æç›®å½•åŠå…¶å­ç›®å½•ä¸­çš„æ‰€æœ‰txtæ–‡ä»¶"""
    txt_files = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith('.txt'):
                txt_files.append(os.path.join(root, file))
    return txt_files

def process_file(file_path, client, system_prompt, model_id):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶è¿”å›AIå“åº”"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': content}
            ],
            stream=False
        )
        
        return completion.choices[0].message.content
    except Exception as e:
        return f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"

def save_response(file_path, response):
    """å°†å“åº”ä¿å­˜ä¸ºmdæ–‡ä»¶"""
    # è·å–åŸæ–‡ä»¶æ‰€åœ¨ç›®å½•å’Œæ–‡ä»¶å
    directory = os.path.dirname(file_path)
    filename = os.path.basename(file_path)
    # ç›´æ¥å°†.txtæ›¿æ¢ä¸º.md
    md_filename = filename.replace('.txt', '.md')
    md_path = os.path.join(directory, md_filename)
    
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(response)
    
    return md_path

def load_providers():
    """åŠ è½½AIæä¾›è€…é…ç½®"""
    config = load_config()
    providers = config.get('providers', {})
    # åˆå¹¶é»˜è®¤æä¾›è€…å’Œè‡ªå®šä¹‰æä¾›è€…
    all_providers = {**DEFAULT_PROVIDERS, **providers}
    return all_providers

def save_provider(name, base_url, models):
    """ä¿å­˜è‡ªå®šä¹‰AIæä¾›è€…"""
    config = load_config()
    if 'providers' not in config:
        config['providers'] = {}
    
    config['providers'][name] = {
        "base_url": base_url,
        "models": models
    }
    save_config(config)

def get_provider_api_key(provider_name):
    """è·å–æä¾›è€…çš„API key"""
    config = load_config()
    provider_keys = config.get('provider_keys', {})
    return provider_keys.get(provider_name, '')

def save_provider_api_key(provider_name, api_key):
    """ä¿å­˜æä¾›è€…çš„API key"""
    config = load_config()
    if 'provider_keys' not in config:
        config['provider_keys'] = {}
    config['provider_keys'][provider_name] = api_key
    save_config(config)

def main():
    st.set_page_config(page_title="AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹", layout="wide")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.title("âš™ï¸ é…ç½®")
        
        # AIæä¾›è€…é…ç½®
        st.subheader("AIæä¾›è€…è®¾ç½®")
        
        # åŠ è½½æ‰€æœ‰æä¾›è€…
        all_providers = load_providers()
        selected_provider = st.selectbox(
            "é€‰æ‹©AIæä¾›è€…",
            options=list(all_providers.keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæœåŠ¡æä¾›å•†"
        )
        
        # é€‰æ‹©æ¨¡å‹
        provider_config = all_providers[selected_provider]
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=list(provider_config["models"].keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
        )
        
        # API Keyè®¾ç½®
        current_api_key = get_provider_api_key(selected_provider)
        api_key = st.text_input(
            f"{selected_provider} API Key", 
            value=current_api_key,
            type="password",
            help=f"è¾“å…¥{selected_provider}çš„APIå¯†é’¥"
        )
        
        if api_key != current_api_key:
            save_provider_api_key(selected_provider, api_key)
            st.success("API Keyå·²ä¿å­˜")
        
        # æ·»åŠ æ–°çš„æä¾›è€…
        with st.expander("æ·»åŠ æ–°çš„AIæä¾›è€…"):
            new_provider_name = st.text_input("æä¾›è€…åç§°")
            new_provider_base_url = st.text_input("Base URL")
            
            # åˆå§‹åŒ–session state
            if 'new_models' not in st.session_state:
                st.session_state.new_models = {}
            
            # æ˜¾ç¤ºå½“å‰å·²æ·»åŠ çš„æ¨¡å‹
            if st.session_state.new_models:
                st.write("å·²æ·»åŠ çš„æ¨¡å‹ï¼š")
                for model_name, model_id in st.session_state.new_models.items():
                    st.write(f"- {model_name}: {model_id}")
            
            # åŠ¨æ€æ¨¡å‹é…ç½®
            st.subheader("é…ç½®æ¨¡å‹")
            
            col1, col2 = st.columns(2)
            with col1:
                model_name = st.text_input("æ¨¡å‹æ˜¾ç¤ºåç§°")
            with col2:
                model_id = st.text_input("æ¨¡å‹ID")
            
            if st.button("æ·»åŠ æ¨¡å‹", key="add_model_btn") and model_name and model_id:
                st.session_state.new_models[model_name] = model_id
                st.success(f"å·²æ·»åŠ æ¨¡å‹: {model_name}")
                st.rerun()
            
            # æ¸…é™¤æ¨¡å‹æŒ‰é’®
            if st.session_state.new_models and st.button("æ¸…é™¤æ‰€æœ‰æ¨¡å‹", type="secondary", key="clear_models_btn"):
                st.session_state.new_models = {}
                st.rerun()
            
            # ä¿å­˜æä¾›è€…æŒ‰é’®
            if st.button("ä¿å­˜æä¾›è€…", type="primary", key="save_provider_btn"):
                if new_provider_name and new_provider_base_url and st.session_state.new_models:
                    save_provider(new_provider_name, new_provider_base_url, st.session_state.new_models)
                    # æ¸…ç©ºsession state
                    st.session_state.new_models = {}
                    st.success("ä¿å­˜æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„æä¾›è€…ä¿¡æ¯å¹¶è‡³å°‘æ·»åŠ ä¸€ä¸ªæ¨¡å‹")
        
        st.markdown("---")
        
        # Promptç®¡ç†
        st.subheader("Promptç®¡ç†")
        
        # åŠ è½½è‡ªå®šä¹‰prompts
        custom_prompts = load_custom_prompts()
        all_prompts = {**DEFAULT_PROMPTS, **custom_prompts}
        
        # Prompté€‰æ‹©
        selected_prompt_name = st.selectbox(
            "é€‰æ‹©System Prompt",
            options=list(all_prompts.keys()),
            help="é€‰æ‹©é¢„è®¾çš„promptæˆ–æ·»åŠ è‡ªå®šä¹‰prompt"
        )
        selected_prompt = all_prompts[selected_prompt_name]
        
        with st.expander("æŸ¥çœ‹å½“å‰Promptå†…å®¹"):
            st.text_area(
                "å½“å‰System Prompt",
                value=selected_prompt,
                height=100,
                disabled=True
            )
        
        # åˆ é™¤è‡ªå®šä¹‰promptçš„æŒ‰é’®
        if selected_prompt_name in custom_prompts:
            if st.button(f"ğŸ—‘ï¸ åˆ é™¤ '{selected_prompt_name}'", type="secondary", key=f"delete_prompt_{selected_prompt_name}"):
                del custom_prompts[selected_prompt_name]
                save_custom_prompts(custom_prompts)
                st.success(f"å·²åˆ é™¤ '{selected_prompt_name}'")
                st.rerun()
        
        # æ·»åŠ æ–°çš„prompt
        with st.expander("æ·»åŠ æ–°çš„Prompt"):
            new_prompt_name = st.text_input(
                "Promptåç§°",
                help="ä¸ºæ–°çš„promptèµ·ä¸€ä¸ªåå­—"
            )
            new_prompt_content = st.text_area(
                "Promptå†…å®¹",
                height=100,
                help="è¾“å…¥promptçš„å…·ä½“å†…å®¹"
            )
            
            if st.button("ğŸ’¾ ä¿å­˜", type="primary", key="save_prompt_btn"):
                if new_prompt_name and new_prompt_content:
                    if new_prompt_name in DEFAULT_PROMPTS:
                        st.error("ä¸èƒ½è¦†ç›–é¢„è®¾çš„Prompt")
                    else:
                        custom_prompts[new_prompt_name] = new_prompt_content
                        save_custom_prompts(custom_prompts)
                        st.success("ä¿å­˜æˆåŠŸï¼")
                        st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„Promptä¿¡æ¯")
    
    # ä¸»ç•Œé¢
    st.title("ğŸ“ AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹")
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    1. åœ¨ä¾§è¾¹æ é…ç½®API Keyå’Œé€‰æ‹©åˆé€‚çš„Prompt
    2. è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶ç›®å½•è·¯å¾„
    3. ç‚¹å‡»å¼€å§‹å¤„ç†
    
    ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š
    - æ‰«æç›®å½•ä¸‹æ‰€æœ‰txtæ–‡ä»¶
    - ä½¿ç”¨AIå¤„ç†æ–‡ä»¶å†…å®¹
    - å°†ç»“æœä¿å­˜ä¸ºåŒåçš„mdæ–‡ä»¶
    """)
    
    # ç›®å½•é€‰æ‹©
    directory = st.text_input(
        "ğŸ“ å¤„ç†ç›®å½•",
        help="è¾“å…¥è¦å¤„ç†çš„ç›®å½•çš„å®Œæ•´è·¯å¾„ï¼Œç³»ç»Ÿå°†å¤„ç†è¯¥ç›®å½•ä¸‹æ‰€æœ‰çš„txtæ–‡ä»¶"
    )
    
    col1, col2 = st.columns([1, 3])
    with col1:
        start_button = st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", key="start_process_btn", disabled=not (api_key and directory))
    
    if not api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®API Key")
    if not directory:
        st.warning("âš ï¸ è¯·è¾“å…¥è¦å¤„ç†çš„ç›®å½•è·¯å¾„")
    
    if start_button:
        try:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–AIå®¢æˆ·ç«¯..."):
                client = OpenAI(
                    api_key=api_key,
                    base_url=all_providers[selected_provider]["base_url"]
                )
            
            # è·å–é€‰ä¸­çš„æ¨¡å‹ID
            model_id = all_providers[selected_provider]["models"][selected_model]
            
            # æ‰«ææ–‡ä»¶
            with st.spinner("æ­£åœ¨æ‰«ææ–‡ä»¶..."):
                txt_files = scan_txt_files(directory)
            
            if not txt_files:
                st.warning("ğŸ“‚ æœªæ‰¾åˆ°txtæ–‡ä»¶")
                return
            
            st.info(f"æ‰¾åˆ° {len(txt_files)} ä¸ªtxtæ–‡ä»¶")
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ›å»ºä¸€ä¸ªåŒºåŸŸæ˜¾ç¤ºå¤„ç†ç»“æœ
            results_area = st.empty()
            processed_files = []
            
            for i, file_path in enumerate(txt_files):
                status_text.text(f"â³ æ­£åœ¨å¤„ç†: {file_path}")
                
                # å¤„ç†æ–‡ä»¶
                response = process_file(file_path, client, all_prompts[selected_prompt_name], model_id)
                
                # ä¿å­˜å“åº”
                md_path = save_response(file_path, response)
                processed_files.append((file_path, md_path))
                
                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(txt_files)
                progress_bar.progress(progress)
                
                # æ›´æ–°å¤„ç†ç»“æœæ˜¾ç¤º
                results_df = pd.DataFrame(
                    processed_files,
                    columns=['æºæ–‡ä»¶', 'ç»“æœæ–‡ä»¶']
                )
                results_area.dataframe(
                    results_df,
                    hide_index=True,
                    use_container_width=True
                )
            
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")
            st.success(f"æˆåŠŸå¤„ç† {len(txt_files)} ä¸ªæ–‡ä»¶")
            
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    main() 