import streamlit as st
import os
import json
from openai import OpenAI
from pathlib import Path
import pandas as pd

# é¢„è®¾çš„system prompts
DEFAULT_PROMPTS = {
    "æ–‡ç« æ€»ç»“": "You are an expert at summarizing text. Please provide a concise summary in Chinese.",
    "ä»£ç åˆ†æž": "You are a code review expert. Please analyze the code and provide suggestions.",
    "é€šç”¨åŠ©æ‰‹": "You are a helpful assistant.",
    "æ–‡æ¡£è½¬æ–‡ç¨¿": "å°†ç”¨æˆ·è¾“å…¥çš„å†…å®¹è½¬æ¢ä¸ºæ–‡ç¨¿ï¼Œè¦æ±‚æœ€å¤§ç¨‹åº¦çš„ä¿ç•™ä¿¡æ¯å®Œæ•´ï¼Œä½†ä¸åŒ…å«ä»»ä½•mdæ ¼å¼ï¼Œä¸è¦ä½¿ç”¨åˆ—è¡¨æ ¼å¼ã€‚å¦‚æžœæœ‰emojiï¼Œåˆ™è½¬æ¢ä¸ºç›¸åº”æ–‡æœ¬ã€‚è¡¨ç¤ºç®­å¤´çš„ç¬¦å·ç»„åˆï¼Œä¾‹å¦‚ï¼š'->'ä½¿ç”¨'>'è¡¨ç¤ºï¼Œ'<-'ä½¿ç”¨'<'è¡¨ç¤ºã€‚",
}

# AIæä¾›è€…é…ç½®
DEFAULT_PROVIDERS = {
    "é˜¿é‡Œé€šä¹‰": {
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "models": {
            "é€šä¹‰åƒé—®Plus": "qwen-plus",
            "é€šä¹‰åƒé—®Turbo": "qwen-turbo",
            "é€šä¹‰åƒé—®Max": "qwen-max"
        }
    },
    "DeepSeek": {
        "base_url": "https://api.deepseek.com",
        "models": {
            "DeepSeek Chat": "deepseek-chat"
        }
    },
    "æ™ºè°±AI": {
        "base_url": "https://open.bigmodel.cn/api/paas/v3/model-api",
        "models": {
            "æ™ºè°±ChatGLM Turbo": "chatglm_turbo",
            "æ™ºè°±ChatGLM Pro": "chatglm_pro",
            "æ™ºè°±ChatGLM Std": "chatglm_std"
        }
    },
    "ç¡…åŸºæµåŠ¨": {
        "base_url": "https://api.siliconflow.cn/v1",
        "models": {
            "Hunyuan-A13B-Instruct": "tencent/Hunyuan-A13B-Instruct",
            "Qwen3-Next-80B-A3B-Instruct": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "Qwen3-Omni-30B-A3B-Thinking": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
            "Qwen3-Omni-30B-A3B-Instruct": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
            "DeepSeek-V3": "deepseek-ai/DeepSeek-V3"
        }
    }
}

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception:
        pass
    return {'custom_prompts': {}, 'providers': {}, 'provider_keys': {}}

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    with open('config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

def load_custom_prompts():
    """åŠ è½½ä¿å­˜çš„è‡ªå®šä¹‰prompts"""
    config = load_config()
    return config.get('custom_prompts', {})

def save_custom_prompts(prompts):
    """ä¿å­˜è‡ªå®šä¹‰prompts"""
    config = load_config()
    config['custom_prompts'] = prompts
    save_config(config)

def scan_files_by_extension(directory, extensions):
    """æ‰«æç›®å½•åŠå…¶å­ç›®å½•ä¸­æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶
    Args:
        directory: ç›®å½•è·¯å¾„
        extensions: æ‰©å±•ååˆ—è¡¨ï¼Œå¦‚ ['txt', 'srt']ï¼ˆä¸åŒ…å«ç‚¹ï¼‰
    """
    matched_files = []
    extensions = [ext.lower() if ext.startswith('.') else f'.{ext.lower()}' for ext in extensions]
    for root, dirs, files in os.walk(directory):
        for file in files:
            file_ext = os.path.splitext(file)[1].lower()
            if file_ext in extensions:
                matched_files.append(os.path.join(root, file))
    return matched_files

def process_file(file_path, client, system_prompt, model_id, temperature=0.7):
    """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶è¿”å›žAIå“åº”"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': content}
            ],
            temperature=temperature,
            stream=False
        )
        
        return completion.choices[0].message.content
    except Exception as e:
        return f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"

def save_response(file_path, response, output_format='md'):
    """å°†å“åº”ä¿å­˜ä¸ºæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶
    Args:
        file_path: åŽŸæ–‡ä»¶è·¯å¾„
        response: AIå“åº”å†…å®¹
        output_format: è¾“å‡ºæ–‡ä»¶æ ¼å¼ï¼Œå¦‚ 'md', 'txt', 'srt' ç­‰ï¼ˆä¸åŒ…å«ç‚¹ï¼‰
    """
    # èŽ·å–åŽŸæ–‡ä»¶æ‰€åœ¨ç›®å½•å’Œæ–‡ä»¶å
    directory = os.path.dirname(file_path)
    filename = os.path.basename(file_path)
    
    # èŽ·å–åŽŸæ–‡ä»¶çš„æ‰©å±•åï¼ˆå¦‚ .txt, .srt ç­‰ï¼‰
    file_ext = os.path.splitext(filename)[1]
    file_name_without_ext = os.path.splitext(filename)[0]
    
    # å¦‚æžœæ²¡æœ‰åŒ…å«ç‚¹ï¼Œè‡ªåŠ¨æ·»åŠ 
    if not output_format.startswith('.'):
        output_format = f'.{output_format}'
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_filename = file_name_without_ext + output_format
    output_path = os.path.join(directory, output_filename)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(response)
    
    return output_path

def load_providers():
    """åŠ è½½AIæä¾›è€…é…ç½®"""
    config = load_config()
    providers = config.get('providers', {})
    # åˆå¹¶é»˜è®¤æä¾›è€…å’Œè‡ªå®šä¹‰æä¾›è€…
    all_providers = {**DEFAULT_PROVIDERS, **providers}
    return all_providers

def save_provider(name, base_url, models):
    """ä¿å­˜è‡ªå®šä¹‰AIæä¾›è€…"""
    config = load_config()
    if 'providers' not in config:
        config['providers'] = {}
    
    config['providers'][name] = {
        "base_url": base_url,
        "models": models
    }
    save_config(config)

def get_provider_api_key(provider_name):
    """èŽ·å–æä¾›è€…çš„API key"""
    config = load_config()
    provider_keys = config.get('provider_keys', {})
    return provider_keys.get(provider_name, '')

def save_provider_api_key(provider_name, api_key):
    """ä¿å­˜æä¾›è€…çš„API key"""
    config = load_config()
    if 'provider_keys' not in config:
        config['provider_keys'] = {}
    config['provider_keys'][provider_name] = api_key
    save_config(config)

def get_model_temperature():
    """èŽ·å–æ¨¡åž‹æ¸©åº¦è®¾ç½®"""
    config = load_config()
    model_settings = config.get('model_settings', {})
    return model_settings.get('temperature', 0.7)

def save_model_temperature(temperature):
    """ä¿å­˜æ¨¡åž‹æ¸©åº¦è®¾ç½®"""
    config = load_config()
    if 'model_settings' not in config:
        config['model_settings'] = {}
    config['model_settings']['temperature'] = temperature
    save_config(config)

def main():
    st.set_page_config(page_title="AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹", layout="wide")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.title("âš™ï¸ é…ç½®")
        
        # AIæä¾›è€…é…ç½®
        st.subheader("AIæä¾›è€…è®¾ç½®")
        
        # åŠ è½½æ‰€æœ‰æä¾›è€…
        all_providers = load_providers()
        selected_provider = st.selectbox(
            "é€‰æ‹©AIæä¾›è€…",
            options=list(all_providers.keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæœåŠ¡æä¾›å•†"
        )
        
        # é€‰æ‹©æ¨¡åž‹
        provider_config = all_providers[selected_provider]
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡åž‹",
            options=list(provider_config["models"].keys()),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡åž‹"
        )
        
        # API Keyè®¾ç½®
        current_api_key = get_provider_api_key(selected_provider)
        api_key = st.text_input(
            f"{selected_provider} API Key", 
            value=current_api_key,
            type="password",
            help=f"è¾“å…¥{selected_provider}çš„APIå¯†é’¥"
        )
        
        if api_key != current_api_key:
            save_provider_api_key(selected_provider, api_key)
            st.success("API Keyå·²ä¿å­˜")
        
        # æ¨¡åž‹æ¸©åº¦è®¾ç½®
        st.divider()
        st.subheader("æ¨¡åž‹å‚æ•°è®¾ç½®")
        
        current_temperature = get_model_temperature()
        temperature = st.slider(
            "æ¨¡åž‹æ¸©åº¦",
            min_value=0.0,
            max_value=2.0,
            value=current_temperature,
            step=0.1,
            help="æ¸©åº¦å€¼æŽ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ã€‚0è¡¨ç¤ºç¡®å®šæ€§è¾“å‡ºï¼ˆæœ€ç¨³å®šï¼‰ï¼Œ2è¡¨ç¤ºé«˜éšæœºæ€§ï¼ˆæœ€åˆ›æ„ï¼‰ã€‚å»ºè®®å€¼ï¼š\n- æ€»ç»“ï¼š0.3-0.5ï¼ˆè¾ƒä½Žï¼‰\n- åˆ›æ„å†™ä½œï¼š1.0-1.5ï¼ˆè¾ƒé«˜ï¼‰\n- å¸¸è§„ä»»åŠ¡ï¼š0.7-0.8ï¼ˆé€‚ä¸­ï¼‰"
        )
        
        if temperature != current_temperature:
            save_model_temperature(temperature)
            st.success(f"æ¸©åº¦å·²è®¾ç½®ä¸º {temperature}")
        
        # æ–‡ä»¶ç±»åž‹é€‰æ‹©
        st.divider()
        st.subheader("æ–‡ä»¶ç±»åž‹é€‰æ‹©")
        
        file_type_option = st.radio(
            "é€‰æ‹©å¤„ç†æ–¹å¼",
            options=["é¢„è®¾ç±»åž‹", "è‡ªå®šä¹‰ç±»åž‹"],
            horizontal=True,
            help="é€‰æ‹©ä½¿ç”¨é¢„è®¾çš„æ–‡ä»¶ç±»åž‹æˆ–è‡ªå®šä¹‰",
            key="file_type_option"
        )
        
        if file_type_option == "é¢„è®¾ç±»åž‹":
            selected_file_types = st.multiselect(
                "é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶ç±»åž‹",
                options=["txt", "srt", "md", "log"],
                default=["txt"],
                help="é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ç±»åž‹",
                key="preset_file_types"
            )
        else:
            custom_types_input = st.text_input(
                "è¾“å…¥æ–‡ä»¶æ‰©å±•åï¼ˆé€—å·åˆ†éš”ï¼‰",
                value="txt,srt",
                placeholder="ä¾‹ï¼štxt,srt,md,log",
                help="è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•åï¼Œç”¨é€—å·åˆ†éš”",
                key="custom_file_types"
            )
            selected_file_types = [t.strip() for t in custom_types_input.split(',') if t.strip()]
        
        if not selected_file_types:
            st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ–‡ä»¶ç±»åž‹")
            selected_file_types = ["txt"]  # é»˜è®¤å€¼
        
        # è¾“å‡ºæ ¼å¼é€‰æ‹©
        st.divider()
        st.subheader("è¾“å‡ºæ ¼å¼è®¾ç½®")
        
        output_format_option = st.radio(
            "é€‰æ‹©è¾“å‡ºæ ¼å¼æ–¹å¼",
            options=["é¢„è®¾æ ¼å¼", "è‡ªå®šä¹‰æ ¼å¼"],
            horizontal=True,
            help="é€‰æ‹©ä½¿ç”¨é¢„è®¾çš„è¾“å‡ºæ ¼å¼æˆ–è‡ªå®šä¹‰",
            key="output_format_option"
        )
        
        if output_format_option == "é¢„è®¾æ ¼å¼":
            selected_output_format = st.selectbox(
                "é€‰æ‹©è¾“å‡ºæ–‡ä»¶æ ¼å¼",
                options=["md", "txt", "srt", "log"],
                index=0,
                help="æ‰€æœ‰å¤„ç†ç»“æžœéƒ½å°†ä¿å­˜ä¸ºé€‰ä¸­çš„æ ¼å¼",
                key="preset_output_format"
            )
        else:
            custom_output_format = st.text_input(
                "è¾“å…¥è¾“å‡ºæ–‡ä»¶æ‰©å±•å",
                value="md",
                placeholder="ä¾‹ï¼šmd, txt, srt",
                help="è¾“å…¥è¾“å‡ºæ–‡ä»¶çš„æ‰©å±•åï¼ˆä¸åŒ…å«ç‚¹ï¼‰",
                key="custom_output_format"
            )
            selected_output_format = custom_output_format.strip().lstrip('.')
        
        if not selected_output_format:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„è¾“å‡ºæ ¼å¼")
            selected_output_format = "md"  # é»˜è®¤å€¼
        
        st.markdown("---")

        # æ·»åŠ æ–°çš„æä¾›è€…
        with st.expander("æ·»åŠ æ–°çš„AIæä¾›è€…"):
            new_provider_name = st.text_input("æä¾›è€…åç§°")
            new_provider_base_url = st.text_input("Base URL")
            
            # åˆå§‹åŒ–session state
            if 'new_models' not in st.session_state:
                st.session_state.new_models = {}
            
            # æ˜¾ç¤ºå½“å‰å·²æ·»åŠ çš„æ¨¡åž‹
            if st.session_state.new_models:
                st.write("å·²æ·»åŠ çš„æ¨¡åž‹ï¼š")
                for model_name, model_id in st.session_state.new_models.items():
                    st.write(f"- {model_name}: {model_id}")
            
            # åŠ¨æ€æ¨¡åž‹é…ç½®
            st.subheader("é…ç½®æ¨¡åž‹")
            
            col1, col2 = st.columns(2)
            with col1:
                model_name = st.text_input("æ¨¡åž‹æ˜¾ç¤ºåç§°")
            with col2:
                model_id = st.text_input("æ¨¡åž‹ID")
            
            if st.button("æ·»åŠ æ¨¡åž‹", key="add_model_btn") and model_name and model_id:
                st.session_state.new_models[model_name] = model_id
                st.success(f"å·²æ·»åŠ æ¨¡åž‹: {model_name}")
                st.rerun()
            
            # æ¸…é™¤æ¨¡åž‹æŒ‰é’®
            if st.session_state.new_models and st.button("æ¸…é™¤æ‰€æœ‰æ¨¡åž‹", type="secondary", key="clear_models_btn"):
                st.session_state.new_models = {}
                st.rerun()
            
            # ä¿å­˜æä¾›è€…æŒ‰é’®
            if st.button("ä¿å­˜æä¾›è€…", type="primary", key="save_provider_btn"):
                if new_provider_name and new_provider_base_url and st.session_state.new_models:
                    save_provider(new_provider_name, new_provider_base_url, st.session_state.new_models)
                    # æ¸…ç©ºsession state
                    st.session_state.new_models = {}
                    st.success("ä¿å­˜æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„æä¾›è€…ä¿¡æ¯å¹¶è‡³å°‘æ·»åŠ ä¸€ä¸ªæ¨¡åž‹")
        
        st.markdown("---")
        
        # Promptç®¡ç†
        st.subheader("Promptç®¡ç†")
        
        # åŠ è½½è‡ªå®šä¹‰prompts
        custom_prompts = load_custom_prompts()
        all_prompts = {**DEFAULT_PROMPTS, **custom_prompts}
        
        # Prompté€‰æ‹©
        selected_prompt_name = st.selectbox(
            "é€‰æ‹©System Prompt",
            options=list(all_prompts.keys()),
            help="é€‰æ‹©é¢„è®¾çš„promptæˆ–æ·»åŠ è‡ªå®šä¹‰prompt"
        )
        selected_prompt = all_prompts[selected_prompt_name]
        
        with st.expander("æŸ¥çœ‹å½“å‰Promptå†…å®¹"):
            st.text_area(
                "å½“å‰System Prompt",
                value=selected_prompt,
                height=100,
                disabled=True
            )
        
        # åˆ é™¤è‡ªå®šä¹‰promptçš„æŒ‰é’®
        if selected_prompt_name in custom_prompts:
            if st.button(f"ðŸ—‘ï¸ åˆ é™¤ '{selected_prompt_name}'", type="secondary", key=f"delete_prompt_{selected_prompt_name}"):
                del custom_prompts[selected_prompt_name]
                save_custom_prompts(custom_prompts)
                st.success(f"å·²åˆ é™¤ '{selected_prompt_name}'")
                st.rerun()
        
        # æ·»åŠ æ–°çš„prompt
        with st.expander("æ·»åŠ æ–°çš„Prompt"):
            new_prompt_name = st.text_input(
                "Promptåç§°",
                help="ä¸ºæ–°çš„promptèµ·ä¸€ä¸ªåå­—"
            )
            new_prompt_content = st.text_area(
                "Promptå†…å®¹",
                height=100,
                help="è¾“å…¥promptçš„å…·ä½“å†…å®¹"
            )
            
            if st.button("ðŸ’¾ ä¿å­˜", type="primary", key="save_prompt_btn"):
                if new_prompt_name and new_prompt_content:
                    if new_prompt_name in DEFAULT_PROMPTS:
                        st.error("ä¸èƒ½è¦†ç›–é¢„è®¾çš„Prompt")
                    else:
                        custom_prompts[new_prompt_name] = new_prompt_content
                        save_custom_prompts(custom_prompts)
                        st.success("ä¿å­˜æˆåŠŸï¼")
                        st.rerun()
                else:
                    st.warning("è¯·å¡«å†™å®Œæ•´çš„Promptä¿¡æ¯")
    
    # ä¸»ç•Œé¢
    st.title("ðŸ“ AIæ‰¹é‡æ€»ç»“åŠ©æ‰‹")
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜Ž
    1. åœ¨ä¾§è¾¹æ é…ç½®API Keyå’Œé€‰æ‹©åˆé€‚çš„Prompt
    2. è¾“å…¥è¦å¤„ç†çš„æ–‡ä»¶ç›®å½•è·¯å¾„
    3. ç‚¹å‡»å¼€å§‹å¤„ç†
    
    ç³»ç»Ÿå°†è‡ªåŠ¨ï¼š
    - æ‰«æç›®å½•ä¸‹æ‰€æœ‰txtæ–‡ä»¶
    - ä½¿ç”¨AIå¤„ç†æ–‡ä»¶å†…å®¹
    - å°†ç»“æžœä¿å­˜ä¸ºåŒåçš„mdæ–‡ä»¶
    """)
    
    # ç›®å½•é€‰æ‹©
    directory = st.text_input(
        "ðŸ“ å¤„ç†ç›®å½•",
        help="è¾“å…¥è¦å¤„ç†çš„ç›®å½•çš„å®Œæ•´è·¯å¾„ï¼Œç³»ç»Ÿå°†å¤„ç†è¯¥ç›®å½•ä¸‹æ‰€æœ‰çš„txtæ–‡ä»¶"
    )
    
    col1, col2 = st.columns([1, 3])
    with col1:
        start_button = st.button("ðŸš€ å¼€å§‹å¤„ç†", type="primary", key="start_process_btn", disabled=not (api_key and directory))
    
    if not api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®API Key")
    if not directory:
        st.warning("âš ï¸ è¯·è¾“å…¥è¦å¤„ç†çš„ç›®å½•è·¯å¾„")
    
    if start_button:
        try:
            with st.spinner("æ­£åœ¨åˆå§‹åŒ–AIå®¢æˆ·ç«¯..."):
                client = OpenAI(
                    api_key=api_key,
                    base_url=all_providers[selected_provider]["base_url"]
                )
            
            # èŽ·å–é€‰ä¸­çš„æ¨¡åž‹ID
            model_id = all_providers[selected_provider]["models"][selected_model]
            
            # èŽ·å–æ¸©åº¦è®¾ç½®
            temperature = get_model_temperature()
            
            # æ‰«ææ–‡ä»¶
            with st.spinner("æ­£åœ¨æ‰«ææ–‡ä»¶..."):
                matched_files = scan_files_by_extension(directory, selected_file_types)
            
            if not matched_files:
                file_types_str = ", ".join(selected_file_types)
                st.warning(f"ðŸ“‚ æœªæ‰¾åˆ°æŒ‡å®šç±»åž‹çš„æ–‡ä»¶ï¼ˆ{file_types_str}ï¼‰")
                return
            
            file_types_str = ", ".join(selected_file_types)
            st.info(f"æ‰¾åˆ° {len(matched_files)} ä¸ªæ–‡ä»¶ ({file_types_str})ï¼Œè¾“å‡ºæ ¼å¼: .{selected_output_format}ï¼Œä½¿ç”¨æ¸©åº¦å€¼: {temperature}")
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # åˆ›å»ºä¸€ä¸ªåŒºåŸŸæ˜¾ç¤ºå¤„ç†ç»“æžœï¼ˆåŒ…å«çŠ¶æ€ï¼‰
            results_area = st.empty()
            processed_files = []
            skipped_count = 0

            for i, file_path in enumerate(matched_files):
                status_text.text(f"â³ æ­£åœ¨å¤„ç†: {file_path}")

                # ç”Ÿæˆå¯¹åº”çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„
                file_dir = os.path.dirname(file_path)
                file_name = os.path.basename(file_path)
                file_name_without_ext = os.path.splitext(file_name)[0]
                output_filename = file_name_without_ext + f'.{selected_output_format}'
                output_path = os.path.join(file_dir, output_filename)

                # å¦‚æžœå·²å­˜åœ¨åŒåè¾“å‡ºæ–‡ä»¶ï¼Œåˆ™è·³è¿‡å¤„ç†
                if os.path.exists(output_path):
                    skipped_count += 1
                    processed_files.append((file_path, output_path, 'è·³è¿‡-å·²å­˜åœ¨'))
                else:
                    # å¤„ç†æ–‡ä»¶
                    response = process_file(file_path, client, all_prompts[selected_prompt_name], model_id, temperature)

                    # ä¿å­˜å“åº”ï¼Œä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºæ ¼å¼
                    output_path = save_response(file_path, response, selected_output_format)
                    processed_files.append((file_path, output_path, 'å·²å¤„ç†'))

                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(matched_files)
                progress_bar.progress(progress)

                # æ›´æ–°å¤„ç†ç»“æžœæ˜¾ç¤º
                results_df = pd.DataFrame(
                    processed_files,
                    columns=['æºæ–‡ä»¶', 'ç»“æžœæ–‡ä»¶', 'çŠ¶æ€']
                )
                results_area.dataframe(
                    results_df,
                    hide_index=True,
                    use_container_width=True
                )
            
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")
            st.success(f"å®Œæˆï¼šå…±æ‰«æ {len(matched_files)} ä¸ªæ–‡ä»¶ï¼Œå·²å¤„ç† {len(matched_files)-skipped_count} ä¸ªï¼Œè·³è¿‡ {skipped_count} ä¸ªï¼ˆå·²å­˜åœ¨åŒåmdï¼‰")
            
        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    main() 